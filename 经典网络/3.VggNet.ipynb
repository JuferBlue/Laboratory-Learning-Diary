{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VggNet",
   "id": "9409ff14b9152497"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:43.209583Z",
     "start_time": "2024-07-23T11:29:43.174896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入相关的包\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "\n",
    "# 指定训练设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "f7f5d8da2718b09f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:44.252805Z",
     "start_time": "2024-07-23T11:29:43.211562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对图片的预处理\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 导入数据集\n",
    "train_data = torchvision.datasets.CIFAR10(root='../数据集/cifar10', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../数据集/cifar10', train=False, transform=transform, download=True)\n"
   ],
   "id": "afe6384d2d8c2b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:44.256425Z",
     "start_time": "2024-07-23T11:29:44.253890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存数据集的长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(\"训练数据集的长度为：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度为：{}\".format(test_data_size))"
   ],
   "id": "144626c01a7dd38f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度为：50000\n",
      "测试数据集的长度为：10000\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:44.260151Z",
     "start_time": "2024-07-23T11:29:44.257367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建数据加载器\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ],
   "id": "22fad1bf4915a4b5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:44.264412Z",
     "start_time": "2024-07-23T11:29:44.261021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义vgg块\n",
    "# num_convs：卷积层的个数\n",
    "# in_channels：输入通道数\n",
    "# out_channels：输出通道数\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = [] # 创建一个列表，用于存放vgg块中的卷积层和池化层\n",
    "    for i in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ],
   "id": "b5716e088e18fa95",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:29:45.023484Z",
     "start_time": "2024-07-23T11:29:44.265788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vgg块的参数\n",
    "conv_arch = ((1,64), (1,128), (2,256), (2,512), (2,512))\n",
    "# vgg模型\n",
    "def vgg(conv_arch):\n",
    "    conv_blocks = [] # 创建一个列表，用于存放vgg块\n",
    "    in_channels = 3 # 输入通道数\n",
    "    # 遍历conv_arch，创建vgg块\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blocks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        *conv_blocks,\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(out_channels*7*7, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10)\n",
    "    )\n",
    "\n",
    "vgg11 = vgg(conv_arch)\n",
    "vgg11 = vgg11.to(device)"
   ],
   "id": "6f0e7ef292b5bf50",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:31:27.978101Z",
     "start_time": "2024-07-23T11:31:27.853699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 观察每一层输出的形状\n",
    "x = torch.randn(size=(1, 3, 224, 224), device=device)\n",
    "for blk in vgg11:\n",
    "    x = blk(x)\n",
    "    print(blk.__class__.__name__, 'output shape: \\t\\t', x.shape)"
   ],
   "id": "1aaf927e457a5f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape: \t\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape: \t\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape: \t\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape: \t\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape: \t\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape: \t\t torch.Size([1, 25088])\n",
      "Linear output shape: \t\t torch.Size([1, 4096])\n",
      "ReLU output shape: \t\t torch.Size([1, 4096])\n",
      "Dropout output shape: \t\t torch.Size([1, 4096])\n",
      "Linear output shape: \t\t torch.Size([1, 4096])\n",
      "ReLU output shape: \t\t torch.Size([1, 4096])\n",
      "Dropout output shape: \t\t torch.Size([1, 4096])\n",
      "Linear output shape: \t\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:31:30.388583Z",
     "start_time": "2024-07-23T11:31:30.384028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型参数\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "vgg11.apply(init_weights)"
   ],
   "id": "54da106a97840440",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (5): Flatten(start_dim=1, end_dim=-1)\n",
       "  (6): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Dropout(p=0.5, inplace=False)\n",
       "  (9): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T11:31:32.321780Z",
     "start_time": "2024-07-23T11:31:32.318373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(vgg11.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 设置训练网络的循环次数\n",
    "epoch = 30"
   ],
   "id": "955fb26f4fc2103d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 开始训练\n",
    "for i in range(epoch):\n",
    "    # 训练过程\n",
    "    print(\"------第{}轮训练开始------\".format(i+1))\n",
    "    vgg11.train()\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        output = vgg11(imgs)\n",
    "        loss = loss_fn(output, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，loss：{}\".format(total_train_step, loss.item()))\n",
    "    \n",
    "    # 测试过程\n",
    "    vgg11.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        total_accuracy = 0\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = vgg11(imgs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (output.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy.item()\n",
    "            total_test_step += 1\n",
    "            \n",
    "    # 输出一个轮次的信息\n",
    "    print(f\"整体测试集上的loss:{total_test_loss}\")\n",
    "    print(f\"整体测试集上的正确率:{total_accuracy/test_data_size}\")\n",
    "    total_test_step += 1\n",
    "    \n",
    "    # 创建文件夹用来保存模型\n",
    "    dir_path = os.path.join(\".\", \"模型保存\", \"3-VggNet\")\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # 保存每一轮的模型\n",
    "    torch.save(vgg11.state_dict(), f\"./模型保存/3-VggNet/vggnet{i}.pth\")\n",
    "    print(\"模型保存成功\")\n",
    "    "
   ],
   "id": "7c9f181440aa0c58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
